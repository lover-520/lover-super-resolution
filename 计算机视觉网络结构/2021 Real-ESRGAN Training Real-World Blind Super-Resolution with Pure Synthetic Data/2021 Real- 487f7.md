# 2021 Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data

[toc]

## Information

* è®ºæ–‡æœŸåˆŠï¼šICCV
* è®ºæ–‡é“¾æ¥ï¼š[Real-ESRGAN](https://openaccess.thecvf.com/content/ICCV2021W/AIM/html/Wang_Real-ESRGAN_Training_Real-World_Blind_Super-Resolution_With_Pure_Synthetic_Data_ICCVW_2021_paper.html)
* è®ºæ–‡ä»£ç ï¼š[code](https://github.com/xinntao/Real-ESRGAN)

## Comments

* æ–‡ç« ä»åˆæˆæ•°æ®çš„é™çº§æ¨¡å‹ç€æ‰‹ï¼Œä½œè€…å¯¹è‡ªå·±18å¹´çš„ESRGANç½‘ç»œè¿›è¡Œäº†æ”¹è¿›ï¼Œæ„Ÿè§‰æ€è·¯æŒºä¸é”™çš„ï¼›ä½œä¸ºä¸€ç¯‡CVPRï¼Œå€¼å¾—ä¸€è¯»ï¼›

## Abstract

> Though many attempts have been made in blind super-resolution to restore low-resolution images with unknown and complex degradations, they are still far from addressing general real-world degraded images. In this work, we extend the powerful ESRGAN to a practical restoration application (namely, Real-ESRGAN), which is trained with pure synthetic data. Specifically, a high-order degradation modeling process is introduced to better simulate complex real-world degradations. We also consider the common ringing and overshoot artifacts in the synthesis process. In addition,we employ a U-Net discriminator with spectral normalization to increase discriminator capability and stabilize the training dynamics. Extensive comparisons have shown its superior visual performance than prior works on variousreal datasets. We also provide efficient implementations tosynthesize training pairs on the fly.
>

ç›²è¶…åˆ†è¾¨ç‡ä»ä½åˆ†è¾¨ç‡å½±åƒä¸­é‡å»ºé«˜åˆ†è¾¨ç‡å½±åƒï¼Œä½åˆ†è¾¨ç‡å½±åƒæ˜¯ç”±é«˜åˆ†è¾¨ç‡å½±åƒé€šè¿‡æœªçŸ¥çš„ä¸”å¤æ‚çš„é€€åŒ–å¾—åˆ°ï¼Œç›®å‰æŠ€æœ¯è¿˜ä¸èƒ½è§£å†³çœŸå®çš„é€€åŒ–å›¾åƒé—®é¢˜ã€‚æœ¬å·¥ä½œä¸­

1. æå‡ºäº†å¢å¼ºçš„ESRGANï¼Œåœ¨çº¯åˆæˆæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒ;
2. **å»ºç«‹ä¸€ç§é«˜é˜¶é€€åŒ–æ¨¡å‹è¿‡ç¨‹ï¼Œæ›´å¥½åœ°æ¨¡æ‹Ÿå¤æ‚çš„ç°å®ä¸–ç•Œé€€åŒ–è¿‡ç¨‹ï¼›(è€ƒè™‘åˆæˆè¿‡ç¨‹ä¸­çš„æŒ¯é“ƒå’Œä¼ªå½±ç°è±¡)**
3. **ä½¿ç”¨å¸¦å…‰è°±å½’ä¸€åŒ–çš„UNetç»“æ„æå‡é‰´åˆ«å™¨çš„æ€§èƒ½å’Œè®­ç»ƒçš„ç¨³å®šæ€§ï¼›**

## Introduction

> Single image super-resolution (SR) is an active research topic, which aims at reconstructing a high resolution (HR) image from its low-resolution (LR) counterpart. Since the pioneering work of SRCNN, deep convolution neural network (CNN) approaches have brought prosperous developments in the SR field. However, ***most approaches assume an ideal bicubic downsampling kernel, which is different from real degradations.*** This degradation mismatch makes those approaches unpractical in real-world scenarios.
>

ç›®å‰å­˜åœ¨é—®é¢˜ï¼šåˆæˆæ•°æ®æ—¶ï¼Œæ™®éå‡è®¾ä¸€ä¸ªç†æƒ³çš„åŒä¸‰æ¬¡ä¸‹é‡‡æ ·æ ¸ï¼Œæ˜æ˜¾ä¸çœŸå®ä¸–ç•Œä¸åˆ

<aside>
ğŸ’¡ **Blind super-resolution, on the contrary, aims to restore low-resolution images suffering from unknown and complex degradations**. Existing approaches can be roughly categorized into **explicit modeling** and **implicit modeling**, according to the underlying degradation process. Classical degradation model, which consists of blur, downsampling, noise and JPEG compression, is widely adopted in explicit modeling methods. However, the real-world degradations are usually too complex to be modeled with a simple combination of multiple degradations. Thus, these methods will easily fail in real-world samples. Implicit modeling methods utilize data distribution learning with Generative Adversarial Network (GAN) to obtain the degradation model. Yet, they are limited to the degradations within training datasets, and could not generalize well to out-of-distribution images.

</aside>

ç›²è¶…åˆ†ï¼Œæ¢å¤é­å—æœªçŸ¥å’Œå¤æ‚é€€åŒ–çš„ä½åˆ†è¾¨ç‡å›¾åƒã€‚åˆ†ä¸ºæ˜¾å¼æ¨¡å‹å’Œéšå¼æ¨¡å‹ï¼šæ˜¾å¼æ¨¡å‹è¯´æ˜æ¨¡ç³Šã€ä¸‹é‡‡æ ·ã€å™ªå£°å’ŒJEPGå‹ç¼©çš„è¿‡ç¨‹ï¼Œä½†ä¸å¤Ÿæè¿°å¤æ‚çš„çœŸå®ä¸–ç•Œå›¾åƒé€€åŒ–è¿‡ç¨‹ï¼›éšå¼æ¨¡å‹é‡‡ç”¨GANç½‘ç»œè·å¾—é€€åŒ–æ¨¡å‹ï¼Œä½†è¢«å±€é™åœ¨è®­ç»ƒé›†ä¸­çš„é€€åŒ–è¿‡ç¨‹ä¸­ï¼›

> To summarize, in this work, 1) we propose a high-order degradation process to model practical degradations, and utilize sinc filters to model common ringing and overshoot artifacts. 2) We employ several essential modifications (e.g., U-Net discriminator with spectral normalization) to increase discriminator capability and stabilize the training dynamics. 3) Real-ESRGAN trained with pure synthetic data is able to restore most real-world images and achieve better visual performance than previous works, making it more practical in real-world applications.
>

æ–‡ç« è´¡çŒ®ï¼š

1. æå‡ºäº†é«˜é˜¶é€€åŒ–æ¨¡å‹å¯¹å®é™…é€€åŒ–è¿›è¡Œå»ºæ¨¡ï¼Œé‡‡ç”¨sincæ»¤æ³¢å™¨åˆ¶é€ å¸¸è§çš„æŒ¯é“ƒå’Œè¿‡å†²ä¼ªå½±ç°è±¡ï¼›
2. å¯¹æ¨¡å‹è¿›è¡Œäº†é€‚é‡çš„ä¿®æ”¹ï¼Œé‡‡ç”¨å¸¦æœ‰å…‰è°±å½’ä¸€åŒ–çš„U-Neté‰´åˆ«å™¨æå‡é‰´åˆ«èƒ½åŠ›å’Œç¨³å®šè®­ç»ƒè¿‡ç¨‹ï¼›
3. é‡‡ç”¨åˆæˆæ•°æ®è¿›è¡Œè®­ç»ƒçš„Real-ESRGANåœ¨å®é™…ä¸–ç•Œä¸Šå…·æœ‰æ›´å®é™…æ€§çš„åº”ç”¨ï¼›

## Methodology

> Blind SR aims to restore high-resolution images from low-resolution ones with unknown and complex degradations. The classical degradation model is usuallyadopted to synthesize the low-resolution input. Generally, the ground-truth image y is first convolved with blur kernel k. Then, a downsampling operation with scale factor r is performed. The low-resolution x is obtained by adding noise n. Finally, JPEG compression is also adopted, as it is widely-used in real-world images.
>

$$
x = D(y) = [(y âŠ› k) â†“r +n]JPEG
$$

å¸¸è§„çš„é€€åŒ–æ¨¡å‹ï¼Œfirst-orderï¼Œxä»£è¡¨é™çº§åçš„å›¾åƒï¼ŒDä»£è¡¨é™çº§å‡½æ•°ï¼Œyä»£è¡¨åŸå§‹å›¾åƒï¼›kä»£è¡¨æ¨¡ç³Šæ ¸ï¼Œrä»£è¡¨ç¼©å°æ¯”ä¾‹ï¼Œnä»£è¡¨åŠ å…¥çš„å™ªå£°ï¼ŒJPEGä»£è¡¨è¿›è¡Œå‹ç¼©

æ¯ä¸€ç§é™çº§æ¨¡å‹é‡Œé¢éƒ½æœ‰å¤šç§æ“ä½œå¯ä¾›é€‰æ‹©ï¼›

ä½œè€…æå‡ºäº†high-orderæ¨¡å‹ï¼š

$$
x = Dn(y) = (Dn â—¦ Â· Â· Â· â—¦ D2 â—¦ D1)(y)
$$

å¤šæ¬¡é‡‡ç”¨first-orderæ¨¡å‹ï¼Œå®éªŒè¯æ˜é‡‡ç”¨ä¸¤æ¬¡first-orderæ•ˆæœæœ€å¥½ï¼›

![Untitled](2021%20Real-%20487f7/Untitled.png)

ä¸ºè§£å†³æŒ¯é“ƒå’Œè¿‡å†²ä¼ªå½±ç°è±¡ï¼šåœ¨é€€åŒ–æ¨¡å‹ä¸­é‡‡ç”¨sinc filteræ“ä½œï¼Œ

ä¸Šé¢ä¸€è¡Œæ˜¯å›¾åƒä¸­å­˜åœ¨çš„æŒ¯é“ƒå’Œè¿‡å†²ä¼ªå½±ï¼›

ç¬¬äºŒè¡Œæ˜¯sinc filteré‡‡ç”¨ä¸åŒå‚æ•°åˆ¶é€ å‡ºçš„å›¾åƒæŒ¯é“ƒå’Œä¼ªå½±æ•ˆæœï¼Œèƒ½å¤Ÿè¾ƒå¥½åœ°æ¨¡å‹ç¬¬ä¸€è¡Œçš„å‰ä¸¤ç§æƒ…å†µï¼›

sinc filteråœ¨ä¸¤ä¸ªåœ°æ–¹åº”ç”¨åˆ°ï¼Œä¸€æ˜¯Bluræ“ä½œä¹‹åï¼ŒäºŒæ˜¯åœ¨æœ€åçš„æ“ä½œï¼Œæœ€åçš„JPEGå‹ç¼©å’Œsinc filterçš„æ“ä½œçš„å‰åæ˜¯éšæœºçš„ï¼›

![Untitled](2021%20Real-%20487f7/Untitled%201.png)

**ESRGAN generatorï¼š**

é‡‡ç”¨Real-ESRGANçš„ç”Ÿæˆå™¨ç»“æ„ï¼ŒRRDB blockï¼Œå¯¹äºInputå¤šäº†ä¸€ç§é€‰æ‹©ï¼Œè¿™é‡Œçš„Inputä¸æ˜¯åŒæ—¶è¾“å…¥X4ã€X2å’ŒX1çš„æ„æ€ï¼Œè€Œæ˜¯é‡Œé¢çš„ç”Ÿæˆå™¨ç»“æ„æ˜¯ç”Ÿæˆ4å€å›¾åƒçš„ç»“æ„ï¼Œé‚£ä¹ˆå¯¹äºéœ€è¦è¶…åˆ†2å€çš„å›¾åƒï¼Œå…ˆé€šè¿‡å°†å…¶ç¼©å°ä¸¤å€ï¼Œåé¢å°±å¯ä»¥é€šè¿‡ç”Ÿæˆå™¨è¶…åˆ†å››å€ï¼›å¯¹äºX1æ¥è¯´ï¼Œå…ˆç¼©å°å››å€ï¼Œå†é€šè¿‡å››å€è¶…åˆ†å°±å¯ä»¥è¾¾åˆ°X1çš„æ•ˆæœã€‚ç¼©å°çš„æ“ä½œæ˜¯é‡‡ç”¨Pixel Unshuffleæ“ä½œï¼Œè¯¥æ“ä½œä¸Pixel Shuffleæ“ä½œç›¸åï¼Œäºšåƒç´ å·ç§¯Pixel Shuffleæ˜¯å°†ä¸åŒé€šé“æ•°çš„å›¾åƒè¿›è¡Œå‹ç¼©æ‰©å¤§å›¾åƒå°ºå¯¸çš„ï¼ŒN * (C * r * r) * W * H â€”â€”>> N * C * (H * r) * (W * r)ï¼ŒPixel Unshuffleåˆ™æ˜¯ç›¸åçš„æ“ä½œï¼›

![Untitled](2021%20Real-%20487f7/Untitled%202.png)

**U-Net discriminator with spectral normalization (SN)ï¼š**

å¸¦æœ‰è°±å½’ä¸€åŒ–çš„U-Neté‰´åˆ«å™¨ï¼Œè¿™ä¸ªæ²¡ä»€ä¹ˆå¥½è§£é‡Šçš„ï¼Œ

å—è¿™ä¸¤ç¯‡æ–‡ç« çš„å¯å‘ï¼Œé‡‡ç”¨U-Netåœ¨generative adversarial networksä¸­å…·æœ‰è¾ƒå¥½çš„ç»“æœï¼›

Edgar Schonfeld, Bernt Schiele, and Anna Khoreva. A u-net based discriminator for generative adversarial networks. In CVPR, 2020.

Yitong Yan, Chuangchuang Liu, Changyou Chen, Xianfang Sun, Longcun Jin, Peng Xinyi, and Xiang Zhou. Fine-grained attention and feature-sharing generative adversarial networks for single image super-resolution. IEEE Transactions on Multimedia, 2021.

å—è¿™ç¯‡æ–‡ç« çš„å¯å‘ï¼Œåœ¨generative adversarial networksä¸­é‡‡ç”¨è°±å½’ä¸€åŒ–ï¼š

Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for generative adversarial networks. In ICLR, 2018.

![Untitled](2021%20Real-%20487f7/Untitled%203.png)

å®éªŒç»“æœ+å¯¹æ¯”å®éªŒéƒ½è¯´æ˜æ•ˆæœæŒºå¥½ï¼›ç”±äºæŒ‡æ ‡å¹¶ä¸èƒ½åˆç†åœ°è¡¨ç¤ºäººçš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œå› æ­¤ç›´æ¥å±•ç¤ºå‡ºæ¨¡å‹çš„é¢„æµ‹æ•ˆæœå›¾ï¼›

## Loss

ä»£ç ä¸­ç†è§£æ˜¯ï¼š
è¿™ä¸ªç»“æ„æ‰€é‡‡ç”¨çš„æŸå¤±å‡½æ•°åŒ…æ‹¬ä¸‰éƒ¨åˆ†ï¼š
ä¼˜åŒ–ç”Ÿæˆå™¨Gï¼š

1. pixelæŸå¤±ï¼ŒGç”Ÿæˆçš„outputå’Œgtä¹‹é—´çš„L1 lossï¼›
2. perceptual lossï¼ŒGç”Ÿæˆçš„outputå’Œgtä¹‹é—´VGGç½‘ç»œçš„æ„ŸçŸ¥æŸå¤±ï¼›
3. GAN lossï¼Œå°†Gç”Ÿæˆçš„æ–‡ä»¶å’Œå¯¹äºé‰´åˆ«å™¨Dæ¥è¯´çš„çœŸå®æ ‡ç­¾(æ¯”å¦‚è¯´åˆ¤æ–­æ˜¯ç”Ÿæˆçš„å›¾ç‰‡ä¸º0ï¼ŒçœŸå®çš„ä¸º1)åšæ¯”è¾ƒï¼Œè¶Šæ¥è¿‘1è¶Šå¥½ï¼Œè¡¨ç¤ºGç”Ÿæˆçš„å›¾ç‰‡Déƒ½é‰´åˆ«ä¸ºçœŸå®çš„ï¼ŒBSEæŸå¤±ï¼›

ä¼˜åŒ–é‰´åˆ«å™¨Dï¼š

1. realï¼Œå°†gtæ”¾è¿›é‰´åˆ«å™¨ä¸­ï¼Œå¾—åˆ°çš„predä¸1è¿›è¡Œæ¯”è¾ƒï¼Œè¶Šæ¥è¿‘è¶Šå¥½ï¼Œè¡¨ç¤ºDèƒ½å¤Ÿæ­£ç¡®è¯†åˆ«æ˜¯çœŸå®çš„å›¾ç‰‡ï¼›
2. fakeï¼Œå°†Gç”Ÿæˆçš„predæ”¾è¿›é‰´åˆ«å™¨ä¸­ï¼Œå¾—åˆ°çš„predä¸0è¿›è¡Œæ¯”è¾ƒï¼Œè¶Šæ¥è¿‘è¶Šå¥½ï¼Œè¡¨ç¤ºDèƒ½å¤Ÿæ­£ç¡®è¯†åˆ«æ˜¯ç”Ÿæˆçš„å›¾ç‰‡ï¼Œéƒ½æ˜¯BCEæŸå¤±å‡½æ•°ï¼Œç›¸å½“äº2åˆ†ç±»é—®é¢˜ï¼›

## Limitations

Though Real-ESRGAN is able to restore most real world images, it still has some limitations. 1) some restored images (especially building and indoor scenes) have **twisted lines** due to aliasing issues. 2) GAN training introduces **unpleasant artifacts** on some samples. 3) It could not remove **out-of-distribution** complicated degradations in the real world. Even worse, it may amplify these artifacts. These drawbacks have great impact on the practical application of Real-ESRGAN, which are in urgent need to address in future works.

![Untitled](2021%20Real-%20487f7/Untitled%204.png)

## Conclusion

> In this paper, we train the practical Real-ESRGAN for real-world blind super-resolution with pure synthetic training pairs. In order to synthesize more practical degradations, we propose a high-order degradation process and employ sinc filters to model common ringing and overshoot artifacts. We also utilize a U-Net discriminator with spectral normalization regularization to increase discriminator capability and stabilize the training dynamics. Real-ESRGAN trained with synthetic data is able to enhance details while removing annoying artifacts for most real-world images.
>

## My Thought

æ–‡ç« ä¸»è¦åˆ›æ–°ç‚¹åœ¨äºï¼š

å¯¹åˆæˆæ•°æ®é›†æ—¶ï¼Œå¦‚ä½•åˆç†åœ°è¿›è¡Œä¸‹é‡‡æ ·æ¨¡æ‹Ÿæ›´çœŸå®çš„æ•°æ®æå‡ºäº†ä¸€ç§æ–°çš„æ–¹æ³•ï¼›

å¯¹ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä¸­çš„é‰´åˆ«å™¨é‡‡ç”¨U-Netç»“æ„ï¼›
