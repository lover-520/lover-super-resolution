# 2021 Remote Sensing Image Super-Resolution Based on Dense Channel Attention Network

[toc]

## Information

* 论文期刊：remote sensing
* 论文链接：[link](https://www.mdpi.com/2072-4292/8/7/594/pdf)

## Comments

* 这篇文章怎么说呢，中规中矩吧，无非是把通道注意力机制引用进来，实验对比的方法不够新，最新的也是17年，但文章是21年的；过一下就成，这篇文章感觉不必精读；

## Abstract

> In the recent years, convolutional neural networks (CNN)-based super resolution (SR) methods are widely used in the field of remote sensing. However, complicated remote sensing images contain abundant high-frequency details, which are difficult to capture and reconstruct effectively. To address this problem, we propose a **dense channel attention network (DCAN)** to reconstruct high resolution (HR) remote sensing images. The proposed method learns multi-level feature information and pays more attention to the important and useful regions in order to better reconstruct the final image. Specifically, we construct a dense channel attention mechanism (DCAM), which densely uses the feature maps from the channel attention block via skip connection. This mechanism makes better use of multi-level feature maps which contain abundant high-frequency information. Further, we add a spatial attention block, which makes the network have more flexible discriminative ability. Experimental results demonstrate that the proposed DCAN method outperforms several state-of-the-art methods in both quantitative evaluation and visual quality.
>  

遥感影像信息具有复杂的高频细节，很难有效的重建。为了解决这个问题，提出了一种密集通道注意力机制网络DCAN

<aside>

💡 怎么说呢，这摘要给我的感觉就是中规中矩，从摘要的信息来看应该是使用了DenseNet、注意力机制；

</aside>

## Introduction

Deep learning-based SR methods in the field of **remote sensing** also developed fast in recent years.

In 2017, a local-global combined network (LGC) was first proposed by Lei et al. to enhance the spatial resolution of remote sensing images. LGC learns multi-level information including local details and global priors using the skip connection operation.

In 2018, a residual dense backprojection network (RDBPN) was proposed by Pan et al., which consists of several residual dense backprojection blocks that contain the upprojection module and the downprojection module.

In 2020, Zhang et al. proposed a scene adaptive method  via a multi-scale attention network to enhance the SR reconstruction details under the different remote sensing scenes.

Recently, an approach named dense-sampling super resolution network (DSSR)  presented a dense sampling mechanism which reuses an upscaler to upsample and overcome the large-scale remote sensing images SR reconstruction problem. However, the complex spatial distribution of remote sensing images need more attention.

In 2020, a second-order multi-scale super resolution network (SMSR)  was proposed by Dong et al. to reuse the learned multi-level information to the high-frequency regions of remote sensing images. The multi-perception attention network (MPSR)  and the multi-scale residual neural network (MRNN)  are also doing some related work about using multi-scale information. In addition, the generative adversarial network (GAN)-based SR method is used to generate visually pleasing remote sensing images. In 2019, Jiang et al. presented an edge-enhancement generative adversarial network (EEGAN) , which introduces an edge enhancement module to improve the remote sensing images SR performance. In 2020, Lei et al. proposed a coupled-discriminated generative adversarial network (CDGAN)  for solving the discrimination-ambiguity problem for the low-frequency regions in the remote sensing images.

17年，LGC模型提出，学习multi-level信息，通过skip-connection包含局部和全局信息；18年，RDBPN提出了backprojection和upprojection模块；20年，Zhang等采用场景自适应方法，multi-scale attention 多尺度自注意机制，加强不同遥感影像场景下SR重建的细节；DSSR提出dense sampling mechanism密集下采样机制；

second-order multi-scale super resolution network (SMSR)学习multi-level信息，用于遥感影像中的高频区域；multi-perception attention network (MPSR)、multi-scale residual neural network (MRNN) 也采用多尺度信息multi-scale；GAN，19年，edge-enhancement generative adversarial network (EEGAN) 对GAN网络引入边缘增强模块；20年，coupled-discriminated generative adversarial network (CDGAN)解决遥感影像低频区域判别歧义的问题；

Although the above-mentioned methods have good performance, their results can be further improved. First, the distributions of remote sensing images are very complex; therefore, we need more high-frequency details and texture to better reconstruct HR images. Secondly, redundancy feature information are not beneficial to recover details and increase computation cost. So, we propose a dense channel attention network (DCAN) which learns multi-level feature information and pays more attention to the important and useful regions in order to better reconstruct the final image. The major contributions are as follows:

(1) We propose a **DCAN** for SR of the single remote sensing image, which makes full use of the features learned at different depths through densely using multi-level feature information and pay more attention to high-frequency regions. Both quantitative and qualitative evaluations demonstrate the superiority of DCAN over the state-of-the-art methods.
(2) A **dense channel attention mechanism (DCAM)** is proposed to utilize the channel attention block through the dense skip connection manner. This mechanism can increase the flow of information through the network and improve the representation capacity of the network.
(3) A **spatial attention block (SAB)** is added to the network. This helps the network have more flexible discriminative ability for different local regions. It contributes to reconstruct the final image. In addition, this helps the network have more flexible discriminative ability for global structure and focus on high-frequency information from the spatial dimension.

目前存在问题：

1. 遥感影像的分布十分复杂，需要更多的高频细节和纹理信息更好地重建HR；
2. 冗余信息不利于恢复细节并且增大了计算成本；

文章贡献：

1. 提出DCAN网络，并进行了定量和定性分析；
2. 密集通道注意力机制DCAM提出；
3. 空间注意力模块SAB添加到网络中；网络具有更好的判别能力

## Network

![Untitled](2021%20Remot%202c682/Untitled.png)

1. Shallow Feature Extraction

这部分普普通通的卷积提取特征；

1. Deep Feature Extraction

包含a series of Dense Channel Attention blocks (DCABs) 和 a Spatial Attention Block (SAB)

1. Reconstruction

two convolutional layers and a deconvolution layer

![The structure of dense channel attention mechanism (DCAM)](2021%20Remot%202c682/Untitled%201.png)

The structure of dense channel attention mechanism (DCAM)

![The structure of dense channel attention block (DCAB)](2021%20Remot%202c682/Untitled%202.png)

The structure of dense channel attention block (DCAB)

![Untitled](2021%20Remot%202c682/Untitled%203.png)

最后一个输出是最后的DCAB计算输出的，应该不是前面的叠加；

DCAB中，两个卷积层，一个ReLU层；CA模块，然后进行相加；

![The structure of Channel Attention Block (CA)](2021%20Remot%202c682/Untitled%204.png)

The structure of Channel Attention Block (CA)

![Untitled](2021%20Remot%202c682/Untitled%205.png)

![The structure of Spatial Attention Block (SAB)](2021%20Remot%202c682/Untitled%206.png)

The structure of Spatial Attention Block (SAB)

## 评价指标

![Untitled](2021%20Remot%202c682/Untitled%207.png)

实验比较方法不行，最近的方法竟然是17年的方法，关键是这是一篇21的文章；
