# 2021 Remote Sensing Image Super-Resolution Based on Dense Channel Attention Network

[toc]

## Information

* è®ºæ–‡æœŸåˆŠï¼šremote sensing
* è®ºæ–‡é“¾æ¥ï¼š[link](https://www.mdpi.com/2072-4292/8/7/594/pdf)

## Comments

* è¿™ç¯‡æ–‡ç« æ€ä¹ˆè¯´å‘¢ï¼Œä¸­è§„ä¸­çŸ©å§ï¼Œæ— éæ˜¯æŠŠé€šé“æ³¨æ„åŠ›æœºåˆ¶å¼•ç”¨è¿›æ¥ï¼Œå®éªŒå¯¹æ¯”çš„æ–¹æ³•ä¸å¤Ÿæ–°ï¼Œæœ€æ–°çš„ä¹Ÿæ˜¯17å¹´ï¼Œä½†æ–‡ç« æ˜¯21å¹´çš„ï¼›è¿‡ä¸€ä¸‹å°±æˆï¼Œè¿™ç¯‡æ–‡ç« æ„Ÿè§‰ä¸å¿…ç²¾è¯»ï¼›

## Abstract

> In the recent years, convolutional neural networks (CNN)-based super resolution (SR) methods are widely used in the field of remote sensing. However, complicated remote sensing images contain abundant high-frequency details, which are difficult to capture and reconstruct effectively. To address this problem, we propose a **dense channel attention network (DCAN)** to reconstruct high resolution (HR) remote sensing images. The proposed method learns multi-level feature information and pays more attention to the important and useful regions in order to better reconstruct the final image. Specifically, we construct a dense channel attention mechanism (DCAM), which densely uses the feature maps from the channel attention block via skip connection. This mechanism makes better use of multi-level feature maps which contain abundant high-frequency information. Further, we add a spatial attention block, which makes the network have more flexible discriminative ability. Experimental results demonstrate that the proposed DCAN method outperforms several state-of-the-art methods in both quantitative evaluation and visual quality.
>  

é¥æ„Ÿå½±åƒä¿¡æ¯å…·æœ‰å¤æ‚çš„é«˜é¢‘ç»†èŠ‚ï¼Œå¾ˆéš¾æœ‰æ•ˆçš„é‡å»ºã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å¯†é›†é€šé“æ³¨æ„åŠ›æœºåˆ¶ç½‘ç»œDCAN

<aside>

ğŸ’¡ æ€ä¹ˆè¯´å‘¢ï¼Œè¿™æ‘˜è¦ç»™æˆ‘çš„æ„Ÿè§‰å°±æ˜¯ä¸­è§„ä¸­çŸ©ï¼Œä»æ‘˜è¦çš„ä¿¡æ¯æ¥çœ‹åº”è¯¥æ˜¯ä½¿ç”¨äº†DenseNetã€æ³¨æ„åŠ›æœºåˆ¶ï¼›

</aside>

## Introduction

Deep learning-based SR methods in the field of **remote sensing** also developed fast in recent years.

In 2017, a local-global combined network (LGC) was first proposed by Lei et al. to enhance the spatial resolution of remote sensing images. LGC learns multi-level information including local details and global priors using the skip connection operation.

In 2018, a residual dense backprojection network (RDBPN) was proposed by Pan et al., which consists of several residual dense backprojection blocks that contain the upprojection module and the downprojection module.

In 2020, Zhang et al. proposed a scene adaptive method  via a multi-scale attention network to enhance the SR reconstruction details under the different remote sensing scenes.

Recently, an approach named dense-sampling super resolution network (DSSR)  presented a dense sampling mechanism which reuses an upscaler to upsample and overcome the large-scale remote sensing images SR reconstruction problem. However, the complex spatial distribution of remote sensing images need more attention.

In 2020, a second-order multi-scale super resolution network (SMSR)  was proposed by Dong et al. to reuse the learned multi-level information to the high-frequency regions of remote sensing images. The multi-perception attention network (MPSR)  and the multi-scale residual neural network (MRNN)  are also doing some related work about using multi-scale information. In addition, the generative adversarial network (GAN)-based SR method is used to generate visually pleasing remote sensing images. In 2019, Jiang et al. presented an edge-enhancement generative adversarial network (EEGAN) , which introduces an edge enhancement module to improve the remote sensing images SR performance. In 2020, Lei et al. proposed a coupled-discriminated generative adversarial network (CDGAN)  for solving the discrimination-ambiguity problem for the low-frequency regions in the remote sensing images.

17å¹´ï¼ŒLGCæ¨¡å‹æå‡ºï¼Œå­¦ä¹ multi-levelä¿¡æ¯ï¼Œé€šè¿‡skip-connectionåŒ…å«å±€éƒ¨å’Œå…¨å±€ä¿¡æ¯ï¼›18å¹´ï¼ŒRDBPNæå‡ºäº†backprojectionå’Œupprojectionæ¨¡å—ï¼›20å¹´ï¼ŒZhangç­‰é‡‡ç”¨åœºæ™¯è‡ªé€‚åº”æ–¹æ³•ï¼Œmulti-scale attention å¤šå°ºåº¦è‡ªæ³¨æ„æœºåˆ¶ï¼ŒåŠ å¼ºä¸åŒé¥æ„Ÿå½±åƒåœºæ™¯ä¸‹SRé‡å»ºçš„ç»†èŠ‚ï¼›DSSRæå‡ºdense sampling mechanismå¯†é›†ä¸‹é‡‡æ ·æœºåˆ¶ï¼›

second-order multi-scale super resolution network (SMSR)å­¦ä¹ multi-levelä¿¡æ¯ï¼Œç”¨äºé¥æ„Ÿå½±åƒä¸­çš„é«˜é¢‘åŒºåŸŸï¼›multi-perception attention network (MPSR)ã€multi-scale residual neural network (MRNN) ä¹Ÿé‡‡ç”¨å¤šå°ºåº¦ä¿¡æ¯multi-scaleï¼›GANï¼Œ19å¹´ï¼Œedge-enhancement generative adversarial network (EEGAN) å¯¹GANç½‘ç»œå¼•å…¥è¾¹ç¼˜å¢å¼ºæ¨¡å—ï¼›20å¹´ï¼Œcoupled-discriminated generative adversarial network (CDGAN)è§£å†³é¥æ„Ÿå½±åƒä½é¢‘åŒºåŸŸåˆ¤åˆ«æ­§ä¹‰çš„é—®é¢˜ï¼›

Although the above-mentioned methods have good performance, their results can be further improved. First, the distributions of remote sensing images are very complex; therefore, we need more high-frequency details and texture to better reconstruct HR images. Secondly, redundancy feature information are not beneficial to recover details and increase computation cost. So, we propose a dense channel attention network (DCAN) which learns multi-level feature information and pays more attention to the important and useful regions in order to better reconstruct the final image. The major contributions are as follows:

(1) We propose a **DCAN** for SR of the single remote sensing image, which makes full use of the features learned at different depths through densely using multi-level feature information and pay more attention to high-frequency regions. Both quantitative and qualitative evaluations demonstrate the superiority of DCAN over the state-of-the-art methods.
(2) A **dense channel attention mechanism (DCAM)** is proposed to utilize the channel attention block through the dense skip connection manner. This mechanism can increase the flow of information through the network and improve the representation capacity of the network.
(3) A **spatial attention block (SAB)** is added to the network. This helps the network have more flexible discriminative ability for different local regions. It contributes to reconstruct the final image. In addition, this helps the network have more flexible discriminative ability for global structure and focus on high-frequency information from the spatial dimension.

ç›®å‰å­˜åœ¨é—®é¢˜ï¼š

1. é¥æ„Ÿå½±åƒçš„åˆ†å¸ƒååˆ†å¤æ‚ï¼Œéœ€è¦æ›´å¤šçš„é«˜é¢‘ç»†èŠ‚å’Œçº¹ç†ä¿¡æ¯æ›´å¥½åœ°é‡å»ºHRï¼›
2. å†—ä½™ä¿¡æ¯ä¸åˆ©äºæ¢å¤ç»†èŠ‚å¹¶ä¸”å¢å¤§äº†è®¡ç®—æˆæœ¬ï¼›

æ–‡ç« è´¡çŒ®ï¼š

1. æå‡ºDCANç½‘ç»œï¼Œå¹¶è¿›è¡Œäº†å®šé‡å’Œå®šæ€§åˆ†æï¼›
2. å¯†é›†é€šé“æ³¨æ„åŠ›æœºåˆ¶DCAMæå‡ºï¼›
3. ç©ºé—´æ³¨æ„åŠ›æ¨¡å—SABæ·»åŠ åˆ°ç½‘ç»œä¸­ï¼›ç½‘ç»œå…·æœ‰æ›´å¥½çš„åˆ¤åˆ«èƒ½åŠ›

## Network

![Untitled](2021%20Remot%202c682/Untitled.png)

1. Shallow Feature Extraction

è¿™éƒ¨åˆ†æ™®æ™®é€šé€šçš„å·ç§¯æå–ç‰¹å¾ï¼›

1. Deep Feature Extraction

åŒ…å«a series of Dense Channel Attention blocks (DCABs) å’Œ a Spatial Attention Block (SAB)

1. Reconstruction

two convolutional layers and a deconvolution layer

![The structure of dense channel attention mechanism (DCAM)](2021%20Remot%202c682/Untitled%201.png)

The structure of dense channel attention mechanism (DCAM)

![The structure of dense channel attention block (DCAB)](2021%20Remot%202c682/Untitled%202.png)

The structure of dense channel attention block (DCAB)

![Untitled](2021%20Remot%202c682/Untitled%203.png)

æœ€åä¸€ä¸ªè¾“å‡ºæ˜¯æœ€åçš„DCABè®¡ç®—è¾“å‡ºçš„ï¼Œåº”è¯¥ä¸æ˜¯å‰é¢çš„å åŠ ï¼›

DCABä¸­ï¼Œä¸¤ä¸ªå·ç§¯å±‚ï¼Œä¸€ä¸ªReLUå±‚ï¼›CAæ¨¡å—ï¼Œç„¶åè¿›è¡Œç›¸åŠ ï¼›

![The structure of Channel Attention Block (CA)](2021%20Remot%202c682/Untitled%204.png)

The structure of Channel Attention Block (CA)

![Untitled](2021%20Remot%202c682/Untitled%205.png)

![The structure of Spatial Attention Block (SAB)](2021%20Remot%202c682/Untitled%206.png)

The structure of Spatial Attention Block (SAB)

## è¯„ä»·æŒ‡æ ‡

![Untitled](2021%20Remot%202c682/Untitled%207.png)

å®éªŒæ¯”è¾ƒæ–¹æ³•ä¸è¡Œï¼Œæœ€è¿‘çš„æ–¹æ³•ç«Ÿç„¶æ˜¯17å¹´çš„æ–¹æ³•ï¼Œå…³é”®æ˜¯è¿™æ˜¯ä¸€ç¯‡21çš„æ–‡ç« ï¼›
