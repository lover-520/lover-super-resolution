# 2020 PSGAN: A Generative Adversarial Network for Remote Sensing Image Pan-sharpening

[toc]

## Information

* 论文期刊：IEEE Transactions on Geoscience and Remote Sensing
* 论文链接：[PSGAN](https://ieeexplore.ieee.org/abstract/document/9306912)
* 论文代码：[code](https://github.com/zhysora/PSGan-Family)

## Comments

* 文章中第一次尝试将GAN应用于pan-sharpen上，相较于普通的方法还是有很大的提升效果;
* 个人觉得这篇文章最主要的在于在pan-sharpen中使用了GAN网络方法，中间的每种方法的结构都比较简单，以后的工作可考虑使用更为复杂的生成器结构提取更有效的特征，损失函数部分也可进行改进；

## Abstract

> This paper addresses the problem of remote sensing image pan-sharpening from the perspective of generative adversarial learning. We propose a novel deep neural network based method named PSGAN. To the best of our knowledge, this is one of the first attempts at producing high-quality pan-sharpened images with GANs. The PSGAN consists of two components: a generative network (i.e., generator) and a discriminative network
(i.e., discriminator). The generator is designed to accept panchromatic (PAN) and multispectral (MS) images as inputs and maps them to the desired high-resolution (HR) MS images and the discriminator implements the adversarial training strategy for generating higher fidelity pan-sharpened images. In this paper, we evaluate several architectures and designs, namely two-stream input, stacking input, batch normalization layer, and attention mechanism to find the optimal solution for pan-sharpening. Extensive experiments on QuickBird, GaoFen-2, and WorldView-
2 satellite images demonstrate that the proposed PSGANs not only are effective in generating high-quality HR MS images and superior to state-of-the-art methods and also generalize well to full-scale images.
>

摘要写得比较简略，说是第一次尝试使用GAN网络去生成具有高质量的pan-sharpen图片；其余的就没什么重点了；

## Introduction

> Recent studies have suggested that deeper networks will achieve better performance on vision tasks. However, training becomes very difficult with depth increasing. Residual learning ease this problem by introducing shortcut connections between different layers of a network, allowing training networks much deeper than previous ones. Pan-sharpening could also be improved by residual learning. Although, Rao et al. and Wei et al. used the concept ‘residual network’, the networks employed in their methods are built with plain units. The depth of their networks is still shallow. The first attempt at applying the residual network is PanNet. They adopt a similar idea to [36] and [37] but employ ResNet to predict details of the image. In this way, both spatial and spectral information could be preserved well.
>

残差学习能够有效地减小网络难以训练的问题，PanNet第一次使用ResNet的网络结构；

• We address pan-sharpening problem from the perspective of image generation and develop novel generative adversarial networks for solving it.
• To accomplish pan-sharpening with the GAN framework, we design a basic two-stream CNN architecture as the generator to produce high-quality pan-sharpened images and employ a fully convolutional discriminator to learn adaptive loss function for improving the quality of the pan-sharpened images.
• We evaluate various configurations of the proposed PSGAN and distill important factors that affect the performance of the pan-sharpening task.
• We demonstrate that the proposed PSGAN can produce astounding results on pan-sharpening problem. Fig. 1 shows one example result produced by our method. Codes are available.

- 从图像生成和生成对抗网络的角度解决pan-sharpen的问题；
- 设计一种双流CNN结构作为生成器生成高质量的pan-sharpen的图像，采用全卷积鉴别器调整损失函数；
- 测试不同的配置；
- 展示了提出的PSGAN的效果；

## Generative Adversarial Networks

介绍GAN的原理结构，这一部分给我的感觉就是GAN原文中的一部分描述；

## PSGAN

最初的PSGAN网络设计成一种双流结构，两个输入分别是PAN图像和进行了上采样的MS图像，这里MS图像只使用了4个波段；

网络中生成部分所使用的网络结构比较简单，除了残差学习的思想之外，基本上没有其他的花里胡哨的网络结构连接；

![Untitled](2020%20PSGAN%2032245/Untitled.png)

左：FU-PSGAN，将使用插值算法的上采样四倍的MS图像修改为使用学习策略的方法；

右：ST-PSGAN，先将PAN和MS进行堆叠操作，然后采用类似的网络结构；

![Untitled](2020%20PSGAN%2032245/Untitled%201.png)

![Untitled](2020%20PSGAN%2032245/Untitled%202.png)

损失函数，生成器采用像素损失和感知损失，判别器采用L1损失；

## Experiments

数据集：QuickBird、GaoFen-2、WorldView-2(将原始的MS和PAN影像都下采样四倍，那么原始的MS影像就可以当成groundtruth了)

评价指标：SAM、CC、sCC、ERGAS、Q4、QNR...

实验：

Impact of patch size：patchsize越大，图像超分的效果越好；

Impact of number of feature maps and kernel size：kernel size和channel，这里也没有得到固定的结论，在不同的数据集上使用不同的kernel size和channel数目会有不同的效果，个人感觉这部分过于注重参数了；

Batch normalization is harmful：BN层参数较多，摆脱了尺度信息，有利于分类任务，但在图像超分上不适用；

Self-attention is not useful：self-attention、non-local不适用于该任务；